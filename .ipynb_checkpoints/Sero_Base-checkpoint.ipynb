{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def Expand_Contact_Matrices(contactMatrix, p_home, p_reduced, p_full):\n",
    "    ''' \n",
    "    This function expands the 3x3 contact matrices into 5x5 ones by separating\n",
    "    adult contacts based on home, reduced, or full contact probabilities.\n",
    "    '''\n",
    "    \n",
    "    temp_rowexpand = contactMatrix[(0,1,1,1,2),:]\n",
    "    temp_expand = temp_rowexpand[:,(0,1,1,1,2)]\n",
    "    \n",
    "    temp_expand[:,(1,2,3)] = temp_expand[:,(1,2,3)] * np.array((p_home, p_reduced, p_full)).reshape((1,3))\n",
    "    \n",
    "    return(temp_expand)\n",
    "\n",
    "def Expand_10x10(MatA, MatB):\n",
    "    '''\n",
    "    This function interlaces a 5x5 high- and 5x5 low- contact matrix into a single 10x10\n",
    "    '''\n",
    "    ret = np.zeros((5,10))\n",
    "    \n",
    "    # fill columns\n",
    "    ret[:,0::2] = MatA\n",
    "    ret[:,1::2] = MatB\n",
    "    \n",
    "    # fill rows\n",
    "    ret = ret[np.repeat(np.arange(5), 2),:]\n",
    "    \n",
    "    return(ret)\n",
    "\n",
    "def time_switch1(t):\n",
    "    return(0+(t<=intvPars['tStart_test']))\n",
    "\n",
    "def time_switch2(t):\n",
    "    return(0+(t>intvPars['tStart_test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEIR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seir_model_shields_rcfc_nolatent_time(X,t,parsList):\n",
    "    '''\n",
    "    - Subscripts are defined as follows: c = children, a = non-essential adults, rc = reduced contact adults, fc = full contact adults, e = elderly\n",
    "    - For infection equations: The I compartments correspond to infectious periods, not periods in which people are symptomatic\n",
    "    - I's are cases that are severe enough to be documented eventually and Ia are undocumented cases\n",
    "    - Since we are not fitting to data we do not need to model specifically when the cases are documented \n",
    "    - pos indicates people who have tested positive for COVID-19 by antibody test\n",
    "    '''\n",
    "\n",
    "    # Load All Parameter Sets\n",
    "    pars = parsList[0]\n",
    "    epiPars = parsList[1]\n",
    "    contactPars = parsList[2]\n",
    "    intvPars = parsList[3]\n",
    "    \n",
    "    # Update Pars\n",
    "    intvPars['socialDistancing_other_c'] = 1-(0.75*intvPars['c'])\n",
    "    intvPars['p_reduced_c'] = 1-(0.9*intvPars['c'])\n",
    "    \n",
    "    # Load all variables\n",
    "    S_c, S_a, S_rc, S_fc, S_e = X[pars['S_ids']]\n",
    "    E_c, E_a, E_rc, E_fc, E_e = X[pars['E_ids']]\n",
    "    Isym_c, Isym_a, Isym_rc, Isym_fc, Isym_e = X[pars['Isym_ids']]\n",
    "    Iasym_c, Iasym_a, Iasym_rc, Iasym_fc, Iasym_e = X[pars['Iasym_ids']]\n",
    "    Hsub_c, Hsub_a, Hsub_rc, Hsub_fc, Hsub_e = X[pars['Hsub_ids']]\n",
    "    Hcri_c, Hcri_a, Hcri_rc, Hcri_fc, Hcri_e = X[pars['Hcri_ids']]\n",
    "    D_c, D_a, D_rc, D_fc, D_e = X[pars['D_ids']]\n",
    "    R_c, R_a, R_rc, R_fc, R_e = X[pars['R_ids']]\n",
    "\n",
    "    S_c_pos, S_a_pos, S_rc_pos, S_fc_pos, S_e_pos = X[pars['S_pos_ids']]\n",
    "    E_c_pos, E_a_pos, E_rc_pos, E_fc_pos, E_e_pos = X[pars['E_pos_ids']]\n",
    "    Isym_c_pos, Isym_a_pos, Isym_rc_pos, Isym_fc_pos, Isym_e_pos = X[pars['Isym_pos_ids']]\n",
    "    Iasym_c_pos, Iasym_a_pos, Iasym_rc_pos, Iasym_fc_pos, Iasym_e_pos = X[pars['Iasym_pos_ids']]\n",
    "    R_c_pos, R_a_pos, R_rc_pos, R_fc_pos, R_e_pos = X[pars['R_pos_ids']]\n",
    "\n",
    "    # Infectiousness of each subgroup\n",
    "    ifc_c_gen, ifc_a_gen, ifc_rc_gen, ifc_fc_gen, ifc_e_gen = epiPars['asymp_red'] * X[pars['Iasym_ids']] + X[pars['Isym_ids']]\n",
    "    ifc_c_pos, ifc_a_pos, ifc_rc_pos, ifc_fc_pos, ifc_e_pos = epiPars['asymp_red'] * X[pars['Iasym_pos_ids']] + X[pars['Isym_pos_ids']]\n",
    "    ifc_comb = np.array([ifc_c_pos, ifc_c_gen, ifc_a_pos, ifc_a_gen, ifc_rc_pos, ifc_rc_gen, ifc_fc_pos, ifc_fc_gen, ifc_e_pos, ifc_e_gen])\n",
    "\n",
    "    # Totals\n",
    "    tot_c, tot_a, tot_rc, tot_fc, tot_e = [np.sum(X[pars[sub + '_ids']]) for sub in ('c', 'a', 'rc', 'fc', 'e')] # These should be constant\n",
    "    tot_c_gen, tot_a_gen, tot_rc_gen, tot_fc_gen, tot_e_gen = [np.sum(X[pars[sub + '_ids'][np.arange(8)]]) for sub in ('c', 'a', 'rc', 'fc', 'e')]\n",
    "    tot_c_pos, tot_a_pos, tot_rc_pos, tot_fc_pos, tot_e_pos = [np.sum(X[pars[sub + '_ids'][np.arange(start=8,stop=13)]]) for sub in ('c', 'a', 'rc', 'fc', 'e')]\n",
    "    tot_comb = np.array([tot_c_pos, tot_c_gen, tot_a_pos, tot_a_gen, tot_rc_pos, tot_rc_gen, tot_fc_pos, tot_fc_gen, tot_e_pos, tot_e_gen])\n",
    "    \n",
    "    # Released Fraction\n",
    "    frac_released = np.array((tot_c_pos/tot_c, tot_a_pos/tot_a, tot_rc_pos/tot_rc, tot_fc_pos/tot_fc, tot_e_pos/tot_e))\n",
    "    frac_distanced = 1-frac_released\n",
    "    frac_comb = np.stack((frac_released, frac_distanced), axis=-1).flatten() # interleaved\n",
    "    \n",
    "    # Derive contact matrices:\n",
    "    # - Matrix entry i,j is the number of contacts/day that an individual in group i has with group j\n",
    "    # - These are normalized for population size and corrected for symmetry using standard methods\n",
    "    \n",
    "    # These will be useful later\n",
    "    temp_even_10x10_Indices = np.meshgrid(2*np.arange(5), 2*np.arange(5))\n",
    "    temp_rep_0011223344 = np.repeat(np.arange(5), 2)\n",
    "    \n",
    "    # Work Contacts\n",
    "    CM_Work_High = contactPars['WorkContacts_5x5'] * frac_released\n",
    "    CM_Work_Low = contactPars['WorkContacts_5x5'] * frac_distanced\n",
    "    CM_Work_Comb = Expand_10x10(CM_Work_High, CM_Work_Low)\n",
    "    \n",
    "    # Broad Distancing Matrix\n",
    "    # - Children have no work contacts\n",
    "    # - Non-essential workers don't work\n",
    "    # - Reduced contact workers reduce contacts by preduced and those contacts are proportional to \n",
    "    #   prevalence in the population\n",
    "    # - Full contact workers keep all of their baseline contacts\n",
    "    # - The distribution of those contacts is based on prevalence in the population\n",
    "    CM_Work_Comb_Distancing = np.zeros((10,10))\n",
    "    CM_Work_Comb_Distancing[4:6,:] = contactPars['WorkContacts_5x5'][2,temp_rep_0011223344]*frac_comb*intvPars['p_reduced']\n",
    "    CM_Work_Comb_Distancing[6:8,:] = contactPars['WorkContacts_5x5'][3,temp_rep_0011223344]*frac_comb*intvPars['p_full']\n",
    "\n",
    "    # Targeted distancing work\n",
    "    # - DISTANCING CONDITIONAL ON TESTING: People working from home regain their workplace contacts if they test positive \n",
    "    # - People in reduced and full contact occupations have the distribution of their workplace contacts changed by alpha    \n",
    "    # - We use fixed shielding (except we multiply by alpha and not alpha+1), \n",
    "    #   so we correct for the situation where alpha times prevalence is greater than 1\n",
    "    alpha_Scale = frac_released*intvPars['alpha']\n",
    "    alpha_Scale = np.array([1.0 if scale>1 else scale for scale in alpha_Scale])\n",
    "    \n",
    "    temp_rc = CM_Work_Comb[4,:]*intvPars['p_reduced_c']\n",
    "    \n",
    "    CM_Work_Comb_TargetedDistancing = np.zeros((10,10))\n",
    "    CM_Work_Comb_TargetedDistancing[2,:] = np.stack((contactPars['WorkContacts_5x5'][1,:], np.zeros(5)), axis=-1).flatten()\n",
    "    CM_Work_Comb_TargetedDistancing[4:6,0::2] = np.array([temp_rc[2*i] + temp_rc[2*i+1]*alpha_Scale[i] for i in np.arange(5)])\n",
    "    CM_Work_Comb_TargetedDistancing[4:6,1::2] = np.array([temp_rc[2*i] + temp_rc[2*i+1]*(1-alpha_Scale[i]) for i in np.arange(5)])\n",
    "    CM_Work_Comb_TargetedDistancing[6:8,:] = np.copy(CM_Work_Comb_TargetedDistancing[4:6,:])/intvPars['p_reduced_c']\n",
    "    \n",
    "    # School Contacts\n",
    "    CM_School_High = contactPars['SchoolContacts_5x5'] * frac_released\n",
    "    CM_School_Low = contactPars['SchoolContacts_5x5'] * frac_distanced\n",
    "    CM_School_Comb = Expand_10x10(CM_School_High, CM_School_Low)\n",
    "\n",
    "    CM_School_Comb_reopen = np.zeros((10,10))\n",
    "    CM_School_Comb_reopen[temp_even_10x10_Indices] = contactPars['SchoolContacts_5x5'].T # meshgrid transposed\n",
    "        \n",
    "    # Home Contacts\n",
    "    CM_Home_High = contactPars['HomeContacts_5x5'] * frac_released\n",
    "    CM_Home_Low = contactPars['HomeContacts_5x5'] * frac_distanced\n",
    "    CM_Home_Comb = Expand_10x10(CM_Home_High, CM_Home_Low)\n",
    "    \n",
    "    # Other Contacts\n",
    "    CM_Other_High = contactPars['OtherContacts_5x5'] * frac_released\n",
    "    CM_Other_Low = contactPars['OtherContacts_5x5'] * frac_distanced\n",
    "    CM_Other_Comb = Expand_10x10(CM_Other_High, CM_Other_Low)\n",
    "    \n",
    "    CM_Other_Comb_Distancing = np.copy(CM_Other_Comb)*intvPars['socialDistancing_other']\n",
    "    \n",
    "    CM_Other_Comb_TargetedDistancing = Expand_10x10(contactPars['OtherContacts_5x5']*intvPars['socialDistancing_other_c']*alpha_Scale\n",
    "                                                    ,contactPars['OtherContacts_5x5']*intvPars['socialDistancing_other_c']*(1-alpha_Scale))\n",
    "    CM_Other_Comb_TargetedDistancing2 = np.copy(CM_Other_Comb_TargetedDistancing)\n",
    "    CM_Other_Comb_TargetedDistancing2[2*np.arange(5),:] = CM_Other_Comb_TargetedDistancing2[2*np.arange(5),:] / intvPars['socialDistancing_other_c']\n",
    "    \n",
    "    # Matrices Change with respect to Control Strategy\n",
    "    if (t<intvPars['tStart_distancing']):\n",
    "        CM = CM_Work_Comb + CM_School_Comb + CM_Home_Comb + CM_Other_Comb\n",
    "    elif (t < intvPars['tStart_target']):\n",
    "        CM = CM_Work_Comb_Distancing + CM_Home_Comb + CM_Other_Comb_Distancing\n",
    "    elif (t < intvPars['tStart_school']):\n",
    "        CM = CM_Other_Comb_TargetedDistancing2 + CM_Home_Comb + CM_Other_Comb_TargetedDistancing\n",
    "    else:\n",
    "        CM = CM_Other_Comb_TargetedDistancing2 + CM_Home_Comb + CM_Other_Comb_TargetedDistancing + CM_School_Comb_reopen #XXX ori code has baseline\n",
    "\n",
    "    # Force of Infections\n",
    "    tot_comb[0::2] = np.array([1.0 if ifc_in==0 else ifc_in for ifc_in in tot_comb[0::2] ]) # avoid division by 0\n",
    "    foi_comb = np.array([epiPars['q']*np.sum(CM[i,:]*ifc_comb/tot_comb) for i in np.arange(10)])\n",
    "    foi_c_pos, foi_c_gen, foi_a_pos, foi_a_gen, foi_rc_pos, foi_rc_gen, foi_fc_pos, foi_fc_gen, foi_e_pos, foi_e_gen = foi_comb\n",
    "    \n",
    "    # Testing\n",
    "    child_tests = intvPars['daily_tests'] * pars['agestruc'][0] # Get nTests available by group\n",
    "    adult_tests_h = intvPars['daily_tests'] * pars['agestruc'][1] * contactPars['frac_home']\n",
    "    adult_tests_rc = intvPars['daily_tests'] * pars['agestruc'][1] * contactPars['frac_reduced']\n",
    "    adult_tests_fc = intvPars['daily_tests'] * pars['agestruc'][1] * contactPars['frac_full']\n",
    "    el_tests = intvPars['daily_tests'] * pars['agestruc'][2]\n",
    "            \n",
    "    # Divide by people eligible to be tested to get proportion tested per day\n",
    "    test_c = child_tests / np.sum((S_c, E_c, Iasym_c, Hsub_c, Hcri_c, R_c))\n",
    "    test_a = adult_tests_h / np.sum((S_a, E_a, Iasym_a, Hsub_a, Hcri_a, R_a))\n",
    "    test_rc = adult_tests_rc / np.sum((S_rc, E_rc, Iasym_rc, Hsub_rc, Hcri_rc, R_rc))\n",
    "    test_fc = adult_tests_fc / np.sum((S_fc, E_fc, Iasym_fc, Hsub_fc, Hcri_fc, R_fc))\n",
    "    test_e = el_tests / np.sum((S_e, E_e, Iasym_e, Hsub_e, Hcri_e, R_e))\n",
    "    \n",
    "    test_comb = np.array((test_c, test_a, test_rc, test_fc, test_e))\n",
    "    \n",
    "    test_switch1 = time_switch1(t)\n",
    "    test_switch2 = time_switch2(t)\n",
    "\n",
    "    # Model Equations\n",
    "    dS_c, dS_a, dS_rc, dS_fc, dS_e = - foi_comb[1::2]*X[pars['S_ids']] \\\n",
    "                                     - (1-intvPars['specificity'])*test_comb*test_switch2*X[pars['S_ids']]\n",
    "    dE_c, dE_a, dE_rc, dE_fc, dE_e = foi_comb[1::2]*X[pars['S_ids']] \\\n",
    "                                     - epiPars['gamma_e']*X[pars['E_ids']] \\\n",
    "                                     - (1-intvPars['specificity'])*test_comb*test_switch2*X[pars['E_ids']]\n",
    "    dIsym_c, dIsym_a, dIsym_rc, dIsym_fc, dIsym_e = epiPars['gamma_e']*X[pars['E_ids']]*epiPars['p'] \\\n",
    "                                                    - epiPars['gamma_s']*X[pars['Isym_ids']]\n",
    "    dIasym_c, dIasym_a, dIasym_rc, dIasym_fc, dIasym_e = epiPars['gamma_e']*X[pars['E_ids']]*(1-epiPars['p']) \\\n",
    "                                                         - epiPars['gamma_a']*X[pars['Iasym_ids']] \\\n",
    "                                                         - (1-intvPars['specificity'])*test_comb*test_switch2*X[pars['Iasym_ids']]\n",
    "    dHsub_c, dHsub_a, dHsub_rc, dHsub_fc, dHsub_e = epiPars['gamma_s']*X[pars['Isym_ids']]*(epiPars['hosp_frac_5']-epiPars['hosp_crit_5']) \\\n",
    "                                                    + epiPars['gamma_s']*X[pars['Isym_pos_ids']]*(epiPars['hosp_frac_5']-epiPars['hosp_crit_5']) \\\n",
    "                                                    - epiPars['gamma_hs']*X[pars['Hsub_ids']]\n",
    "    dHcri_c, dHcri_a, dHcri_rc, dHcri_fc, dHcri_e = epiPars['gamma_s']*X[pars['Isym_ids']]*epiPars['hosp_crit_5'] \\\n",
    "                                                    + epiPars['gamma_s']*X[pars['Isym_pos_ids']]*epiPars['hosp_crit_5'] \\\n",
    "                                                    - epiPars['gamma_hc']*X[pars['Hcri_ids']]\n",
    "    dD_c, dD_a, dD_rc, dD_fc, dD_e = epiPars['gamma_hc']*X[pars['Hcri_ids']]*epiPars['crit_die_5']\n",
    "    dR_c, dR_a, dR_rc, dR_fc, dR_e = (1-epiPars['hosp_frac_5'])*epiPars['gamma_s']*X[pars['Isym_ids']] \\\n",
    "                                     + epiPars['gamma_a']*X[pars['Iasym_ids']] \\\n",
    "                                     + (1-intvPars['sensitivity'])*test_switch2*epiPars['gamma_hs']*X[pars['Hsub_ids']] \\\n",
    "                                     + (1-intvPars['sensitivity'])*test_switch2*epiPars['gamma_hc']*X[pars['Hcri_ids']]*(1-epiPars['crit_die_5']) \\\n",
    "                                     - intvPars['sensitivity']*test_comb*test_switch2*X[pars['R_ids']] \\\n",
    "                                     + epiPars['gamma_hc']*test_switch1*X[pars['Hcri_ids']]*(1-epiPars['crit_die_5']) \\\n",
    "                                     + test_switch1*epiPars['gamma_hs']*X[pars['Hsub_ids']]\n",
    "\n",
    "    dS_c_pos, dS_a_pos, dS_rc_pos, dS_fc_pos, dS_e_pos = (1-intvPars['specificity'])*test_comb*test_switch2*X[pars['S_ids']] \\\n",
    "                                                         - foi_comb[0::2]*X[pars['S_pos_ids']]\n",
    "    dE_c_pos, dE_a_pos, dE_rc_pos, dE_fc_pos, dE_e_pos = (1-intvPars['specificity'])*test_comb*test_switch2*X[pars['E_ids']] \\\n",
    "                                                         + foi_comb[0::2]*X[pars['S_pos_ids']] \\\n",
    "                                                         - epiPars['gamma_e']*X[pars['E_pos_ids']]\n",
    "    dIsym_c_pos, dIsym_a_pos, dIsym_rc_pos, dIsym_fc_pos, dIsym_e_pos = epiPars['gamma_e']*X[pars['E_pos_ids']]*epiPars['p'] \\\n",
    "                                                                        - epiPars['gamma_s']*X[pars['Isym_pos_ids']]\n",
    "    dIasym_c_pos, dIasym_a_pos, dIasym_rc_pos, dIasym_fc_pos, dIasym_e_pos = (1-intvPars['specificity'])*test_comb*test_switch2*X[pars['Iasym_ids']] \\\n",
    "                                                                             + epiPars['gamma_e']*X[pars['E_pos_ids']]*(1-epiPars['p']) \\\n",
    "                                                                             - epiPars['gamma_a']*X[pars['Iasym_pos_ids']]\n",
    "    dR_c_pos, dR_a_pos, dR_rc_pos, dR_fc_pos, dR_e_pos = intvPars['sensitivity']*test_comb*test_switch2*X[pars['R_ids']] \\\n",
    "                                                         + intvPars['sensitivity']*epiPars['gamma_hc']*test_switch2*X[pars['Hcri_ids']]*(1-epiPars['crit_die_5']) \\\n",
    "                                                         + intvPars['sensitivity']*epiPars['gamma_hs']*test_switch2*X[pars['Hsub_ids']] \\\n",
    "                                                         + (1-epiPars['hosp_frac_5'])*(epiPars['gamma_s']*X[pars['Isym_pos_ids']]) \\\n",
    "                                                         + epiPars['gamma_a']*X[pars['Iasym_pos_ids']]\n",
    "    \n",
    "    dXdt = np.array((dS_c, dS_a, dS_rc, dS_fc, dS_e\n",
    "                   , dE_c, dE_a, dE_rc, dE_fc, dE_e\n",
    "                   , dIsym_c, dIsym_a, dIsym_rc, dIsym_fc, dIsym_e\n",
    "                   , dIasym_c, dIasym_a, dIasym_rc, dIasym_fc, dIasym_e\n",
    "                   , dHsub_c, dHsub_a, dHsub_rc, dHsub_fc, dHsub_e\n",
    "                   , dHcri_c, dHcri_a, dHcri_rc, dHcri_fc, dHcri_e\n",
    "                   , dD_c, dD_a, dD_rc, dD_fc, dD_e\n",
    "                   , dR_c, dR_a, dR_rc, dR_fc, dR_e\n",
    "                   , dS_c_pos, dS_a_pos, dS_rc_pos, dS_fc_pos, dS_e_pos\n",
    "                   , dE_c_pos, dE_a_pos, dE_rc_pos, dE_fc_pos, dE_e_pos\n",
    "                   , dIsym_c_pos, dIsym_a_pos, dIsym_rc_pos, dIsym_fc_pos, dIsym_e_pos\n",
    "                   , dIasym_c_pos, dIasym_a_pos, dIasym_rc_pos, dIasym_fc_pos, dIasym_e_pos\n",
    "                   , dR_c_pos, dR_a_pos, dR_rc_pos, dR_fc_pos, dR_e_pos))\n",
    "  \n",
    "    return dXdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pars\n",
    "pars = {}\n",
    "\n",
    "# Timeline\n",
    "pars['nDays'] = 366 # days\n",
    "\n",
    "# Population Structure\n",
    "pars['N'] = 323*10**6\n",
    "pars['agefrac_0'] = np.array([0.12,0.13,0.13,0.13,0.13,0.13,0.11,0.06,0.04,0.02])\n",
    "pars['agestruc'] = np.array((np.sum(pars['agefrac_0'][0:2])\n",
    "                            , np.sum(pars['agefrac_0'][2:6]) + 0.5*pars['agefrac_0'][6]\n",
    "                            , 0.5*pars['agefrac_0'][6] + np.sum(pars['agefrac_0'][7:10])))\n",
    "\n",
    "# IDs\n",
    "pars['nSubgroups'] = 5 #ALWAYS: c, a, rc, fc, e\n",
    "N = pars['nSubgroups']\n",
    "\n",
    "pars['nCompartments'] = 13 #ALWAYS: S, E, Isym, Iasym, Hsub, Hcri, D, R, S_pos, E_pos, Isym_pos, Iasym_pos, R_pos\n",
    "Nc = pars['nCompartments']\n",
    "\n",
    "# Base Compartment Indices\n",
    "pars['S_ids'] = np.arange(start = (0*N), stop = (1*N))\n",
    "pars['E_ids'] = np.arange(start = (1*N), stop = (2*N))\n",
    "pars['Isym_ids'] = np.arange(start = (2*N), stop = (3*N))\n",
    "pars['Iasym_ids'] = np.arange(start = (3*N), stop = (4*N))\n",
    "pars['Hsub_ids'] = np.arange(start = (4*N), stop = (5*N))\n",
    "pars['Hcri_ids'] = np.arange(start = (5*N), stop = (6*N))\n",
    "pars['D_ids'] = np.arange(start = (6*N), stop = (7*N))\n",
    "pars['R_ids'] = np.arange(start = (7*N), stop = (8*N))\n",
    "\n",
    "# Positive Test Compartment Indices\n",
    "pars['S_pos_ids'] = np.arange(start = (8*N), stop = (9*N))\n",
    "pars['E_pos_ids'] = np.arange(start = (9*N), stop = (10*N))\n",
    "pars['Isym_pos_ids'] = np.arange(start = (10*N), stop = (11*N))\n",
    "pars['Iasym_pos_ids'] = np.arange(start = (11*N), stop = (12*N))\n",
    "pars['R_pos_ids'] = np.arange(start = (12*N), stop = (13*N))\n",
    "\n",
    "\n",
    "# IDs by SubGroup\n",
    "pars['c_ids'] = np.arange(Nc)*N + 0\n",
    "pars['a_ids'] = np.arange(Nc)*N + 1\n",
    "pars['rc_ids'] = np.arange(Nc)*N + 2\n",
    "pars['fc_ids'] = np.arange(Nc)*N + 3\n",
    "pars['e_ids'] = np.arange(Nc)*N + 4\n",
    "\n",
    "pars['nTotSubComp'] = N * Nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epi Pars\n",
    "epiPars = {}\n",
    "\n",
    "epiPars['R0'] = 2.9\n",
    "epiPars['q'] = epiPars['R0']/63.28 # Probability of transmission from children\n",
    "epiPars['asymp_red'] = 0.55        # Relative infectiousness of asymptomatic vs symptomatic case\n",
    "\n",
    "epiPars['gamma_e'] = 1/3           # Latent period (He et al)\n",
    "epiPars['gamma_a']= 1/7            # Recovery rate, undocumented (Kissler et al)\n",
    "epiPars['gamma_s']= 1/7            # Recovery rate, undocumented (Kissler et al)\n",
    "epiPars['gamma_hs']= 1/5           # LOS for subcritical cases (medrxiv paper)\n",
    "epiPars['gamma_hc']= 1/7           # LOS for critical cases (medrxiv paper)\n",
    "epiPars['p'] = 0.3#0.14            # Fraction 'Symptomatic'documented' (Shaman's paper)\n",
    "\n",
    "epiPars['hosp_frac'] = np.array((0.061, 0.182, 0.417))  #From MMWR\n",
    "epiPars['hosp_crit'] = np.array((0, 0.063, 0.173))      #From CDC, MMWR\n",
    "epiPars['crit_die'] = np.array((0, 0.5, 0.5))           #Obtained from initial fitting\n",
    "\n",
    "# Expand epiPars\n",
    "epiPars['hosp_frac_5'] = epiPars['hosp_frac'][np.array((0,1,1,1,2))]\n",
    "epiPars['hosp_crit_5'] = epiPars['hosp_crit'][np.array((0,1,1,1,2))]\n",
    "epiPars['crit_die_5'] = epiPars['crit_die'][np.array((0,1,1,1,2))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contact Interaction Pars\n",
    "contactPars = {}\n",
    "\n",
    "# Contact Matrices: 3x3 data from Prem et al\n",
    "contactPars['AllContacts'] = np.array((9.75, 2.57, 0.82, 5.97, 10.32, 2.25, 0.39, 0.46, 1.20)).reshape((3,3)).T\n",
    "contactPars['WorkContacts'] = np.array((0.20, 0.28, 0, 0.64, 4.73, 0, 0, 0, 0)).reshape((3,3)).T\n",
    "contactPars['SchoolContacts'] = np.array((4.32, 0.47, 0.02, 1.10, 0.32, 0.04, 0.01, 0.01, 0.03)).reshape((3,3)).T\n",
    "contactPars['HomeContacts'] = np.array((2.03, 1.02, 0.50, 2.37, 1.82, 0.68, 0.24, 0.14, 0.62)).reshape((3,3)).T\n",
    "contactPars['OtherContacts'] = np.array((3.20, 0.80, 0.30, 1.86, 3.45, 1.53, 0.14, 0.32, 0.55)).reshape((3,3)).T\n",
    "\n",
    "contactPars['frac_home'] = 0.316\n",
    "contactPars['frac_reduced'] = 0.6275\n",
    "contactPars['frac_full'] = 0.0565\n",
    "\n",
    "# Include Expansions\n",
    "contactPars['WorkContacts_5x5'] = Expand_Contact_Matrices(contactPars['WorkContacts']\n",
    "                                                          , contactPars['frac_home']\n",
    "                                                          , contactPars['frac_reduced']\n",
    "                                                          , contactPars['frac_full'])\n",
    "contactPars['SchoolContacts_5x5'] = Expand_Contact_Matrices(contactPars['SchoolContacts']\n",
    "                                                            , contactPars['frac_home']\n",
    "                                                            , contactPars['frac_reduced']\n",
    "                                                            , contactPars['frac_full'])\n",
    "contactPars['HomeContacts_5x5'] = Expand_Contact_Matrices(contactPars['HomeContacts']\n",
    "                                                          , contactPars['frac_home']\n",
    "                                                          , contactPars['frac_reduced']\n",
    "                                                          , contactPars['frac_full'])\n",
    "contactPars['OtherContacts_5x5'] = Expand_Contact_Matrices(contactPars['OtherContacts']\n",
    "                                                           , contactPars['frac_home']\n",
    "                                                           , contactPars['frac_reduced']\n",
    "                                                           , contactPars['frac_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervention Pars\n",
    "intvPars = {}\n",
    "\n",
    "# Test Data for Cellex\n",
    "intvPars['sensitivity'] = 0.94\n",
    "intvPars['specificity'] = 0.96\n",
    "intvPars['daily_tests'] = 10**3\n",
    "\n",
    "# Other intervention parameters\n",
    "intvPars['tStart_distancing'] = 70\n",
    "intvPars['tStart_target'] = 115\n",
    "intvPars['tStart_school'] = 230\n",
    "\n",
    "intvPars['socialDistancing_other'] = .25\n",
    "intvPars['p_reduced'] = 0.1 # proportion of contacts reduced \n",
    "intvPars['p_full'] = 1 # proportion of contacts reduced for full contact adults\n",
    "\n",
    "intvPars['alpha'] = 4 # shielding. Note this is not alpha_JSW, but (alpha_JSW + 1)\n",
    "intvPars['c'] = 1\n",
    "\n",
    "intvPars['socialDistancing_other_c'] = 1-(0.75*intvPars['c'])\n",
    "intvPars['p_reduced_c'] = 1-(0.9*intvPars['c'])\n",
    "\n",
    "intvPars['tStart_test'] = 107 # can change when in the outbreak testing becomes available\n",
    "intvPars['tStart_target'] = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions\n",
    "inits = {}\n",
    "\n",
    "inits['I_c0'] = 60\n",
    "inits['I_a0'] = 20\n",
    "inits['I_rc0'] = 50\n",
    "inits['I_fc0'] = 1\n",
    "inits['I_e0'] = 40\n",
    "\n",
    "X0 = np.zeros(pars['nTotSubComp'])\n",
    "\n",
    "# Remove from susceptible pool ...\n",
    "X0[0] = pars['agestruc'][0] * pars['N'] - inits['I_c0'] \n",
    "X0[1] = pars['agestruc'][1] * contactPars['frac_home'] * pars['N'] - inits['I_a0'] \n",
    "X0[2] = pars['agestruc'][1] * contactPars['frac_reduced'] * pars['N'] - inits['I_rc0'] \n",
    "X0[3] = pars['agestruc'][1] * contactPars['frac_full'] * pars['N'] - inits['I_fc0'] \n",
    "X0[4] = pars['agestruc'][2] * pars['N'] - inits['I_e0'] \n",
    "\n",
    "# ... and add to infected\n",
    "X0[10] = inits['I_c0']\n",
    "X0[11] = inits['I_a0']\n",
    "X0[12] = inits['I_rc0']\n",
    "X0[13] = inits['I_fc0']\n",
    "X0[14] = inits['I_e0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czhao98/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:98: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "t0 = 0\n",
    "tf = pars['nDays']\n",
    "tstep = 1 # day\n",
    "t = np.arange(t0,tf+tstep, tstep)\n",
    "combPars = list((pars, epiPars, contactPars, intvPars))\n",
    "\n",
    "# Run Model\n",
    "model_out = integrate.odeint(seir_model_shields_rcfc_nolatent_time, X0, t, args=(combPars,))#, rtol = 1, hmax=0.1, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Sweep\n",
    "cvals = np.arange(3)/2\n",
    "    #cvals = np.arange(9)/8\n",
    "    #cvals = np.arange(5)/4\n",
    "    \n",
    "test_rates = np.append(np.array([0]), np.logspace(3,7, 5))\n",
    "    #test_rates = np.append(np.array([0]), np.logspace(1,7, 13))\n",
    "\n",
    "alphas = np.array([4])\n",
    "    #alphas = np.array([0, 0.5, 1, 2, 4, 10, 20])\n",
    "\n",
    "specificities = np.array([0.96])\n",
    "    #specificities = np.array([0.5, 0.75, 0.85, 0.90, 0.96, 1])\n",
    "\n",
    "sensitivities = np.array([0.94])\n",
    "    #sensitivities = np.array([0.5, 0.94])\n",
    "\n",
    "sweep = np.array([(i_c, i_test, i_alpha, i_spec, i_sens) for i_c in cvals for i_test in test_rates for i_alpha in alphas for i_spec in specificities for i_sens in sensitivities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czhao98/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:98: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.555555555555555\n",
      "11.11111111111111\n",
      "16.666666666666664\n",
      "22.22222222222222\n",
      "27.77777777777778\n",
      "33.33333333333333\n",
      "38.88888888888889\n",
      "44.44444444444444\n",
      "50.0\n",
      "55.55555555555556\n",
      "61.111111111111114\n",
      "66.66666666666666\n",
      "72.22222222222221\n",
      "77.77777777777779\n",
      "83.33333333333334\n",
      "88.88888888888889\n",
      "94.44444444444444\n"
     ]
    }
   ],
   "source": [
    "df_sweep = np.zeros((sweep.shape[0], 9))\n",
    "for i in np.arange(sweep.shape[0]):\n",
    "    print(i/sweep.shape[0]*100)\n",
    "    \n",
    "    # Load ins\n",
    "    c_in, test_in, alpha_in, spec_in, sens_in = sweep[i,:]\n",
    "    \n",
    "    # Save to combPars\n",
    "    intvPars['c'] = c_in\n",
    "    intvPars['daily_tests'] = test_in\n",
    "    intvPars['alpha'] = alpha_in\n",
    "    intvPars['specificity'] = spec_in\n",
    "    intvPars['sensitivity'] = sens_in\n",
    "    combPars = list((pars, epiPars, contactPars, intvPars))\n",
    "    \n",
    "    # Run Model\n",
    "    model_out = integrate.odeint(seir_model_shields_rcfc_nolatent_time, X0, t, args=(combPars,))#, rtol = 1, hmax=0.1, )\n",
    "\n",
    "    # Stats\n",
    "    tot_deaths = np.sum(model_out[-1, pars['D_ids']])\n",
    "    \n",
    "    tot_infec = np.sum(model_out[-1,pars['Isym_ids']]\n",
    "                     + model_out[-1,pars['Iasym_ids']]\n",
    "                     + model_out[-1,pars['Hsub_ids']]\n",
    "                     + model_out[-1,pars['Hcri_ids']]\n",
    "                     + model_out[-1,pars['D_ids']]\n",
    "                     + model_out[-1,pars['R_ids']]\n",
    "                     + model_out[-1,pars['Isym_pos_ids']]\n",
    "                     + model_out[-1,pars['Iasym_pos_ids']]\n",
    "                     + model_out[-1,pars['R_pos_ids']])\n",
    "    \n",
    "    tot_cases = np.sum(model_out[-1,pars['Hsub_ids']]\n",
    "                     + model_out[-1,pars['Hcri_ids']]\n",
    "                     + model_out[-1,pars['D_ids']]\n",
    "                     + model_out[-1,pars['Isym_pos_ids']]\n",
    "                     + model_out[-1,pars['Iasym_pos_ids']]\n",
    "                     + model_out[-1,pars['R_pos_ids']])\n",
    "    \n",
    "    tot_released = np.sum(model_out[-1,pars['S_pos_ids']]\n",
    "                      + model_out[-1,pars['E_pos_ids']]\n",
    "                      + model_out[-1,pars['Isym_pos_ids']]\n",
    "                      + model_out[-1,pars['Iasym_pos_ids']]\n",
    "                      + model_out[-1,pars['R_pos_ids']])\n",
    "    \n",
    "    df_sweep[i,:] = [tot_deaths, tot_infec, tot_cases, tot_released, c_in, test_in, alpha_in, spec_in, sens_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Result\n",
    "df_out = pd.DataFrame(df_sweep)\n",
    "df_out.columns = ['Deaths', 'Infected', 'Known_Infection', 'Released', 'c', 'test_rate', 'alpha', 'specificity', 'sensitivity']\n",
    "df_out.to_csv('04_24_2020_ParmSweep_Python.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
